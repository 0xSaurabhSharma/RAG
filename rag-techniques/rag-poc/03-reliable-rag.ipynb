{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment variables set successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# Function to set environment variables\n",
    "def set_env_variables():\n",
    "    os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "    os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')\n",
    "    os.environ['LANGCHAIN_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
    "    os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY', '')\n",
    "\n",
    "    os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY', '')\n",
    "    os.environ['HUGGINGFACEHUB_API_TOKEN'] = os.getenv('HUGGINGFACEHUB_API_TOKEN', '')\n",
    "\n",
    "    print(\"✅ Environment variables set successfully!\")\n",
    "\n",
    "# Call the function\n",
    "set_env_variables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import librairies\n",
    "from langchain.document_loaders import PyPDFLoader, CSVLoader, WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate \n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field , ConfigDict\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# from openai import RateLimitError\n",
    "#from langchain_core.exceptions import LLMError\n",
    "from typing import List\n",
    "from rank_bm25 import BM25Okapi\n",
    "import fitz\n",
    "import asyncio\n",
    "import random\n",
    "import textwrap\n",
    "import numpy as np\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2089/2254272975.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name='BAAI/bge-small-en')\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(model_name='Gemma2-9b-it')\n",
    "embeddings = HuggingFaceEmbeddings(model_name='BAAI/bge-small-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urls\n",
    "urls = [\n",
    "    \"https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?ref=dl-staging-website.ghost.io\",\n",
    "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?ref=dl-staging-website.ghost.io\",\n",
    "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?ref=dl-staging-website.ghost.io\",\n",
    "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/?ref=dl-staging-website.ghost.io\",\n",
    "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/?ref=dl-staging-website.ghost.io\"\n",
    "]\n",
    "\n",
    "# Load\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "splitted_docs = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Vector Store\n",
    "v_store = FAISS.from_documents(splitted_docs, embeddings)\n",
    "retriever = v_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":4}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='689584f8-2fd2-483a-92c5-22fb958f0bac', metadata={'source': 'https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?ref=dl-staging-website.ghost.io', 'title': 'Four AI Agent Strategies That Improve GPT-4 and GPT-3.5 Performance', 'description': 'I think AI agent workflows will drive massive AI progress this year — perhaps even more than the next generation of foundation models. This is an important...', 'language': 'en'}, page_content='up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.Next week, I’ll elaborate on these design patterns and offer suggested readings for each.Keep learning!AndrewRead \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights'), Document(id='5259b3a0-4ff5-491d-b7f4-b18ebfbc199b', metadata={'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 4: Planning', 'description': 'Planning is a key\\xa0agentic AI design pattern\\xa0in which we use a large language model (LLM) to autonomously decide on what sequence of steps to execute...', 'language': 'en'}, page_content='\"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"\\xa0Read \"Agentic Design Patterns Part 3: Tool Use\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout'), Document(id='841768da-15c4-4dbd-9272-36486921bd28', metadata={'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 5, Multi-Agent Collaboration', 'description': 'Multi-agent collaboration is the last of the four\\xa0key AI agentic design patterns\\xa0that I’ve described in recent letters...', 'language': 'en'}, page_content='\"Agentic Design Patterns Part 3: Tool Use\"Read \"Agentic Design Patterns Part 4:\\xa0Planning\" ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout'), Document(id='df236384-8b25-420e-839c-3bfcf1cb0c79', metadata={'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 3: Tool Use', 'description': 'Tool use, in which an LLM is given functions it can request to call for gathering information, taking action, or manipulating data, is a key design...', 'language': 'en'}, page_content='and Multi-agent collaboration design patterns. They allow AI agents to do much more but are less mature, less predictable — albeit very exciting — technologies.\\xa0Keep learning!AndrewRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly')]\n"
     ]
    }
   ],
   "source": [
    "question = \"What are the different kind of agentic design patterns?\"\n",
    "answers = retriever.invoke(question)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id: 689584f8-2fd2-483a-92c5-22fb958f0bac\n",
      "Title: Four AI Agent Strategies That Improve GPT-4 and GPT-3.5 Performance\n",
      "Content: up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.Next week, I’ll elaborate on these design patterns and offer suggested readings for each.Keep learning!AndrewRead \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights\n",
      "\n",
      "Id: 5259b3a0-4ff5-491d-b7f4-b18ebfbc199b\n",
      "Title: Agentic Design Patterns Part 4: Planning\n",
      "Content: \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\" Read \"Agentic Design Patterns Part 3: Tool Use\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout\n",
      "\n",
      "Id: 841768da-15c4-4dbd-9272-36486921bd28\n",
      "Title: Agentic Design Patterns Part 5, Multi-Agent Collaboration\n",
      "Content: \"Agentic Design Patterns Part 3: Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\" ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout\n",
      "\n",
      "Id: df236384-8b25-420e-839c-3bfcf1cb0c79\n",
      "Title: Agentic Design Patterns Part 3: Tool Use\n",
      "Content: and Multi-agent collaboration design patterns. They allow AI agents to do much more but are less mature, less predictable — albeit very exciting — technologies. Keep learning!AndrewRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ans in answers:\n",
    "    print(f\"Id: {ans.id}\\nTitle: {ans.metadata['title']}\\nContent: {ans.page_content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check document relevancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance on retrieved documents.\"\"\"\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "    answers: List[str]\n",
    "    \n",
    "## LLM with structured output\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document:  \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out non-relevant docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.Next week, I’ll elaborate on these design patterns and offer suggested readings for each.Keep learning!AndrewRead \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights \n",
      " --------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes' answers=['Agentic Design Patterns Part 2: Reflection', 'Agentic Design Patterns Part 3, Tool Use', 'Agentic Design Patterns Part 4: Planning', 'Agentic Design Patterns Part 5: Multi-Agent Collaboration'] \n",
      "\n",
      "\"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\" Read \"Agentic Design Patterns Part 3: Tool Use\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout \n",
      " --------------------------------------------------\n",
      "binary_score='yes' answers=['Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance', 'Agentic Design Patterns Part 2: Reflection', 'Agentic Design Patterns Part 3: Tool Use', 'Agentic Design Patterns Part 5: Multi-Agent Collaboration'] \n",
      "\n",
      "\"Agentic Design Patterns Part 3: Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\" ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAbout \n",
      " --------------------------------------------------\n",
      "binary_score='yes' answers=['Agentic Design Patterns Part 3: Tool Use', 'Agentic Design Patterns Part 4: Planning'] \n",
      "\n",
      "and Multi-agent collaboration design patterns. They allow AI agents to do much more but are less mature, less predictable — albeit very exciting — technologies. Keep learning!AndrewRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly \n",
      " --------------------------------------------------\n",
      "binary_score='yes' answers=['Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance', 'Agentic Design Patterns Part 2: Reflection', 'Agentic Design Patterns Part 4: Planning', 'Agentic Design Patterns Part 5: Multi-Agent Collaboration'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs_to_use = []\n",
    "for ans in answers:\n",
    "    print(ans.page_content, '\\n', '-'*50)\n",
    "    res = retrieval_grader.invoke({\"document\":ans.page_content, \"question\":question})\n",
    "    print(res,'\\n')\n",
    "    if res.binary_score == 'yes':\n",
    "        docs_to_use.append(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prompt\n",
    "system = \"\"\"You are an assistant for question-answering tasks. Answer the question based upon your knowledge. \n",
    "Use three-to-five sentences maximum and keep the answer concise.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved documents: \\n\\n <docs>{documents}</docs> \\n\\n User question: <question>{question}</question>\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "## llm\n",
    "llm = ChatGroq(model_name='Gemma2-9b-it', temperature=0)\n",
    "\n",
    "## Post processing\n",
    "def format_docs(answors):\n",
    "    return \"\\n\".join(f'<doc{i+1}>: Title:{doc.metadata['title']}\\nSource:{doc.metadata['source']}\\nContent:{doc.page_content}</doc{i+1}>\\n' for i, doc in enumerate(answers))\n",
    "\n",
    "## Chain\n",
    "rag_chain = prompt | llm | StrOutputParser() \n",
    "\n",
    "## Invoke\n",
    "generation = rag_chain.invoke({\"documents\":format_docs(docs_to_use), \"question\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article outlines five agentic design patterns:  Reflection, Tool Use, Planning, Multi-Agent Collaboration, and  Four AI agent strategies.  These patterns enhance the capabilities of AI agents, allowing them to perform more complex tasks and interact with their environment in sophisticated ways. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data model\n",
    "class GradeHallucinations (BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generated answer.\"\"\"\n",
    "    binary_score: str = Field(..., description=\"Answer contains hallucination, 'yes' or 'no'\")\n",
    "\n",
    "## Structured llm\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "## Prompt \n",
    "system =  \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n \n",
    "    Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
    "\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Answer: {answer} \\n\\n Retrieved documents: \\n\\n <docs>{documents}</docs> \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader\n",
    "\n",
    "response = hallucination_grader.invoke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlight Used Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "## Data Model\n",
    "class HighlightDocuments(BaseModel):\n",
    "    \"\"\"Return the specific part of a document used for answering the question.\"\"\"\n",
    "    id: List[str] = Field(..., description=\"The id of the document used for answering the question.\")\n",
    "    title: List[str] = Field(..., description=\"List of titles of the documents used for answering the question.\")\n",
    "    source: List[str] = Field(..., description=\"List of sources of the documents used for answering the question.\")\n",
    "    segment: List[str] = Field(..., description=\"The specific part of the document used for answering the question.\")\n",
    "    \n",
    "## Custom parser for Pydantic v2\n",
    "class CustomPydanticOutputParser(PydanticOutputParser):\n",
    "    def get_format_instructions(self) -> str:\n",
    "        schema = self.pydantic_object.model_json_schema()\n",
    "        return f\"\"\"The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
    "\n",
    "{schema}\n",
    "\n",
    "As an example, for the schema {{\"properties\": {{\"foo\": {{\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {{\"type\": \"string\"}}}}}}, \"required\": [\"foo\"]}}\n",
    "the object {{\"foo\": [\"bar\", \"baz\"]}} is a well-formatted instance of the schema. The object {{\"properties\": {{\"foo\": [\"bar\", \"baz\"]}}}} is not well-formatted.\n",
    "\n",
    "Please ensure the output is a valid JSON object with the correct schema and not a string representation of it.\"\"\"\n",
    "    \n",
    "# Use the custom parser\n",
    "parser = CustomPydanticOutputParser(pydantic_object=HighlightDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are an advanced assistant for document search and retrieval. You are provided with the following:\n",
    "1. A question.\n",
    "2. A generated answer based on the question.\n",
    "3. A set of documents that were referenced in generating the answer.\n",
    "\n",
    "Your task is to identify and extract the exact inline segments from the provided documents that directly correspond to the content used to \n",
    "generate the given answer. The extracted segments must be verbatim snippets from the documents, ensuring a word-for-word match with the text \n",
    "in the provided documents.\n",
    "\n",
    "Ensure that:\n",
    "- (Important) Each segment is an exact match to a part of the document and is fully contained within the document text.\n",
    "- The relevance of each segment to the generated answer is clear and directly supports the answer provided.\n",
    "- (Important) If you didn't used the specific document don't mention it.\n",
    "\n",
    "Used documents: <docs>{documents}</docs> \\n\\n User question: <question>{question}</question> \\n\\n Generated answer: <answer>{generation}</answer>\n",
    "\n",
    "<format_instruction>\n",
    "{format_instructions}\n",
    "</format_instruction>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=system,\n",
    "    input_variables=[\"documents\", \"question\", \"generation\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Chain\n",
    "doc_lookup = prompt | llm | parser\n",
    "\n",
    "# Run\n",
    "lookup_response = doc_lookup.invoke({\"documents\": format_docs(docs_to_use), \"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: doc1\n",
      "Title: Four AI Agent Strategies That Improve GPT-4 and GPT-3.5 Performance\n",
      "Source: https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?ref=dl-staging-website.ghost.io\n",
      "Text Segment: Next week, I’ll elaborate on these design patterns and offer suggested readings for each.Keep learning!AndrewRead \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for id, title, source, segment in zip(lookup_response.id, lookup_response.title, lookup_response.source, lookup_response.segment):\n",
    "    print(f\"ID: {id}\\nTitle: {title}\\nSource: {source}\\nText Segment: {segment}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
