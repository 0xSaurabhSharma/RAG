{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries & Setting ENV Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment variables set successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# Function to set environment variables\n",
    "def set_env_variables():\n",
    "    os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "    os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')\n",
    "    os.environ['LANGCHAIN_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
    "    os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY', '')\n",
    "\n",
    "    os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY', '')\n",
    "    os.environ['HUGGINGFACEHUB_API_TOKEN'] = os.getenv('HUGGINGFACEHUB_API_TOKEN', '')\n",
    "\n",
    "    print(\"✅ Environment variables set successfully!\")\n",
    "\n",
    "# Call the function\n",
    "set_env_variables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "## import librairies\n",
    "from langchain.document_loaders import PyPDFLoader, CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field \n",
    "from langchain import PromptTemplate\n",
    "# from openai import RateLimitError\n",
    "#from langchain_core.exceptions import LLMError\n",
    "from typing import List\n",
    "from rank_bm25 import BM25Okapi\n",
    "import fitz\n",
    "import asyncio\n",
    "import random\n",
    "import textwrap\n",
    "import numpy as np\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading PDF\n",
    "\n",
    "path = \"../data/Understanding_Climate_Change.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encode Document\n",
    "\n",
    "\n",
    "def replace_t_with_space(list_of_documents):\n",
    "    \"\"\"\n",
    "    Replaces all tab characters ('\\t') with spaces in the page content of each document\n",
    "\n",
    "    Args:\n",
    "        list_of_documents: A list of document objects, each with a 'page_content' attribute.\n",
    "\n",
    "    Returns:\n",
    "        The modified list of documents with tab characters replaced by spaces.\n",
    "    \"\"\"\n",
    "\n",
    "    for doc in list_of_documents:\n",
    "        doc.page_content = doc.page_content.replace('\\t', ' ')  # Replace tabs with spaces\n",
    "    return list_of_documents\n",
    "\n",
    "def encode_pdf(path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Encodes a PDF book into a vector store using OpenAI embeddings.\n",
    "\n",
    "    Args:\n",
    "        path: The path to the PDF file.\n",
    "        chunk_size: The desired size of each text chunk.\n",
    "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
    "\n",
    "    Returns:\n",
    "        A FAISS vector store containing the encoded book content.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load PDF documents\n",
    "    loader = PyPDFLoader(path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
    "    )\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    cleaned_texts = replace_t_with_space(texts)\n",
    "\n",
    "    # Create embeddings (Tested with OpenAI and Amazon Bedrock)\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Create vector store\n",
    "    v_store = FAISS.from_documents(cleaned_texts, embeddings)\n",
    "\n",
    "    return v_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240/432484572.py:44: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb8b9a7cdd645ada8538d026df32656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb468384fb32409bb124d1a6057c4920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad42c2ab6384582899a1c49160924cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288fc59a8ba94a9595a27e0797bf5d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6508e6f6cfc540129c6daa3d8b2af324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e47b66c1eb04eb9a20d948c2c89cd14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e476ab94cf1f4ca7adcfdded559e125a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c7e7fa716f494284a708fb1662054f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ece0d460294a89a5a5baaf5981dd72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72983feeaa248949b901a998288de18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a426f397c46048ccaff899ef1040cee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v_store = encode_pdf(path=path)\n",
    "v_retriever = v_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_retriever = v_store.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context_per_question(question, chunks_query_retriever):\n",
    "    \"\"\"\n",
    "    Retrieves relevant context and unique URLs for a given question using the chunks query retriever.\n",
    "\n",
    "    Args:\n",
    "        question: The question for which to retrieve context and URLs.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "        - A string with the concatenated content of relevant documents.\n",
    "        - A list of unique URLs from the metadata of the relevant documents.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve relevant documents for the given question\n",
    "    docs = chunks_query_retriever.get_relevant_documents(question)\n",
    "\n",
    "    # Concatenate document content\n",
    "    # context = \" \".join(doc.page_content for doc in docs)\n",
    "    context = [doc.page_content for doc in docs]\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3240/3469880042.py:15: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = chunks_query_retriever.get_relevant_documents(question)\n"
     ]
    }
   ],
   "source": [
    "test_query = \"What is climate change ? Why is it important ? How to prevent it ?\"\n",
    "context = retrieve_context_per_question(test_query, v_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chapter 2: Causes of Climate Change \\nGreenhouse Gases \\nThe primary cause of recent climate change is the increase in greenhouse gases in the \\natmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous \\noxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is essential \\nfor life on Earth, as it keeps the planet warm enough to support life. However, human \\nactivities have intensified this natural process, leading to a warmer climate. \\nFossil Fuels \\nBurning fossil fuels for energy releases large amounts of CO2. This includes coal, oil, and \\nnatural gas used for electricity, heating, and transportation. The industrial revolution marked \\nthe beginning of a significant increase in fossil fuel consumption, which continues to rise \\ntoday. \\nCoal',\n",
       " 'The economic costs of climate change include damage to infrastructure, reduced agricultural \\nproductivity, health care costs, and lost labor productivity. Extreme weather events, such as \\nhurricanes and floods, can cause significant economic disruption. Investing in climate action \\nnow can prevent much higher costs in the future. \\nSocial and Environmental Costs \\nClimate change exacerbates social inequalities, with marginalized communities often bearing \\nthe brunt of its impacts. Environmental costs include loss of biodiversity, ecosystem \\ndegradation, and decreased availability of natural resources. Addressing these issues requires \\nintegrated, equitable solutions. \\nBenefits of Climate Action \\nEconomic Opportunities \\nInvesting in renewable energy, energy efficiency, and sustainable practices creates jobs and \\nstimulates economic growth. The transition to a green economy can drive innovation and']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02-simple-rag-csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading PDF\n",
    "\n",
    "from langchain.document_loaders import CSVLoader\n",
    "import pandas as pd\n",
    "path = \"../data/Understanding_Climate_Change.pdf\"\n",
    "csv_path = \"../data/customers-100.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Customer Id</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Phone 1</th>\n",
       "      <th>Phone 2</th>\n",
       "      <th>Email</th>\n",
       "      <th>Subscription Date</th>\n",
       "      <th>Website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>DD37Cf93aecA6Dc</td>\n",
       "      <td>Sheryl</td>\n",
       "      <td>Baxter</td>\n",
       "      <td>Rasmussen Group</td>\n",
       "      <td>East Leonard</td>\n",
       "      <td>Chile</td>\n",
       "      <td>229.077.5154</td>\n",
       "      <td>397.884.0519x718</td>\n",
       "      <td>zunigavanessa@smith.info</td>\n",
       "      <td>2020-08-24</td>\n",
       "      <td>http://www.stephenson.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1Ef7b82A4CAAD10</td>\n",
       "      <td>Preston</td>\n",
       "      <td>Lozano</td>\n",
       "      <td>Vega-Gentry</td>\n",
       "      <td>East Jimmychester</td>\n",
       "      <td>Djibouti</td>\n",
       "      <td>5153435776</td>\n",
       "      <td>686-620-1820x944</td>\n",
       "      <td>vmata@colon.com</td>\n",
       "      <td>2021-04-23</td>\n",
       "      <td>http://www.hobbs.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6F94879bDAfE5a6</td>\n",
       "      <td>Roy</td>\n",
       "      <td>Berry</td>\n",
       "      <td>Murillo-Perry</td>\n",
       "      <td>Isabelborough</td>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>+1-539-402-0259</td>\n",
       "      <td>(496)978-3969x58947</td>\n",
       "      <td>beckycarr@hogan.com</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>http://www.lawrence.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5Cef8BFA16c5e3c</td>\n",
       "      <td>Linda</td>\n",
       "      <td>Olsen</td>\n",
       "      <td>Dominguez, Mcmillan and Donovan</td>\n",
       "      <td>Bensonview</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>001-808-617-6467x12895</td>\n",
       "      <td>+1-813-324-8756</td>\n",
       "      <td>stanleyblackwell@benson.org</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>http://www.good-lyons.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>053d585Ab6b3159</td>\n",
       "      <td>Joanna</td>\n",
       "      <td>Bender</td>\n",
       "      <td>Martin, Lang and Andrade</td>\n",
       "      <td>West Priscilla</td>\n",
       "      <td>Slovakia (Slovak Republic)</td>\n",
       "      <td>001-234-203-0635x76146</td>\n",
       "      <td>001-199-446-3860x3486</td>\n",
       "      <td>colinalvarado@miles.net</td>\n",
       "      <td>2021-04-17</td>\n",
       "      <td>https://goodwin-ingram.com/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index      Customer Id First Name Last Name  \\\n",
       "0      1  DD37Cf93aecA6Dc     Sheryl    Baxter   \n",
       "1      2  1Ef7b82A4CAAD10    Preston    Lozano   \n",
       "2      3  6F94879bDAfE5a6        Roy     Berry   \n",
       "3      4  5Cef8BFA16c5e3c      Linda     Olsen   \n",
       "4      5  053d585Ab6b3159     Joanna    Bender   \n",
       "\n",
       "                           Company               City  \\\n",
       "0                  Rasmussen Group       East Leonard   \n",
       "1                      Vega-Gentry  East Jimmychester   \n",
       "2                    Murillo-Perry      Isabelborough   \n",
       "3  Dominguez, Mcmillan and Donovan         Bensonview   \n",
       "4         Martin, Lang and Andrade     West Priscilla   \n",
       "\n",
       "                      Country                 Phone 1                Phone 2  \\\n",
       "0                       Chile            229.077.5154       397.884.0519x718   \n",
       "1                    Djibouti              5153435776       686-620-1820x944   \n",
       "2         Antigua and Barbuda         +1-539-402-0259    (496)978-3969x58947   \n",
       "3          Dominican Republic  001-808-617-6467x12895        +1-813-324-8756   \n",
       "4  Slovakia (Slovak Republic)  001-234-203-0635x76146  001-199-446-3860x3486   \n",
       "\n",
       "                         Email Subscription Date                      Website  \n",
       "0     zunigavanessa@smith.info        2020-08-24   http://www.stephenson.com/  \n",
       "1              vmata@colon.com        2021-04-23        http://www.hobbs.com/  \n",
       "2          beckycarr@hogan.com        2020-03-25     http://www.lawrence.com/  \n",
       "3  stanleyblackwell@benson.org        2020-06-02   http://www.good-lyons.com/  \n",
       "4      colinalvarado@miles.net        2021-04-17  https://goodwin-ingram.com/  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(csv_path)\n",
    "docs  = loader.load()\n",
    "\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "index = faiss.IndexFlatL2(embeddings.client.get_sentence_embedding_dimension())\n",
    "v_store = FAISS(\n",
    "    embedding_function = embeddings,\n",
    "    index = index,\n",
    "    docstore = InMemoryDocstore(), \n",
    "    index_to_docstore_id = {}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding splitted csv data to vector store\n",
    "\n",
    "v_store.add_documents(documents=docs)\n",
    "retriever = v_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Retrieval Chain\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')\n",
    "llm = ChatGroq(\n",
    "    model_name=\"Gemma2-9b-it\"\n",
    ")\n",
    "\n",
    "\n",
    "# Set up system prompt\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "    \n",
    "])\n",
    "\n",
    "# Create the question-answer chain\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sheryl Baxter works for Rasmussen Group.  This information is found in the provided context under Customer Id: DD37Cf93aecA6Dc. \\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer= rag_chain.invoke({\"input\": \"which company does sheryl Baxter work for?\"})\n",
    "answer['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
